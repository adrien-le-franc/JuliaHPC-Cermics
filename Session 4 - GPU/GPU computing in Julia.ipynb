{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "pregnant-calgary",
   "metadata": {},
   "source": [
    "# GPU computing in Julia\n",
    "\n",
    "## Overview of the landscape\n",
    "\n",
    "- [JuliaGPU](https://juliagpu.org/): Mother organisation\n",
    "- [CUDA](https://github.com/JuliaGPU/CUDA.jl): NVIDIA GPUs, best supported, focus of this talk\n",
    "- [oneAPI](https://github.com/JuliaGPU/oneAPI.jl): Support for Intel GPUs with oneAPI (slightly less functionality and performance)\n",
    "- [AMDGPU](https://github.com/JuliaGPU/AMDGPU.jl): AMD GPUs running on the ROCm stack (experimental)\n",
    "\n",
    "GPU support is heavy work in progress, but user experience with NVIDIA GPUs is already smooth and using them can be highly recommended. With other platforms I'd be careful as of now. That's why we will focus on CUDA.jl here.\n",
    "\n",
    "## Installation\n",
    "\n",
    "Install CUDA package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "criminal-matter",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import Pkg\n",
    "Pkg.add(\"CUDA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "toxic-judgment",
   "metadata": {},
   "source": [
    "Important difference to most other Julia packages: This does *not yet* install the full thing. The reason is that not every computer has a GPU, but packages should still do sth. sensible.\n",
    "\n",
    "We can check wether we have a GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "traditional-camcorder",
   "metadata": {},
   "outputs": [],
   "source": [
    "using CUDA\n",
    "if CUDA.functional()\n",
    "    println(\"Congrats! You have CUDA-enabled GPU!\")\n",
    "else\n",
    "    println(\"Sorry no GPU support detected\")\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "driven-rider",
   "metadata": {},
   "source": [
    "(I will assume from here on that we have a GPU ... most of what I show will crash if you don't)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controlling-hepatitis",
   "metadata": {},
   "source": [
    "Let's see some info about our device:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cellular-treasury",
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA.versioninfo()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "computational-officer",
   "metadata": {},
   "source": [
    "## High-level tour\n",
    "\n",
    "The CUDA.jl package provides equivalent GPU functions and datastructures for a large portion of the standard library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indonesian-station",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = CUDA.randn(3, 3)  # Random matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "capable-princess",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = CUDA.randn(3)   # Random vector\n",
    "A * b   # Matrix-Vector product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expensive-stanley",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(A, dims=2)   # Sum over second dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "linear-watson",
   "metadata": {},
   "outputs": [],
   "source": [
    "A[:, 2]   # Second column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handled-intellectual",
   "metadata": {},
   "outputs": [],
   "source": [
    "A \\ b   # Solve dense linear system"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "humanitarian-hartford",
   "metadata": {},
   "source": [
    "Notice: The default data type on GPUs is **Float32**!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conceptual-support",
   "metadata": {},
   "source": [
    "GPU discouraged features (e.g. scalar indexing) are allowed by default:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "olive-feelings",
   "metadata": {},
   "outputs": [],
   "source": [
    "A[1,1] = 2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "creative-local",
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA.allowscalar(false)  # Disable scalar indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sweet-selection",
   "metadata": {},
   "outputs": [],
   "source": [
    "A[1,1] = 2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blank-option",
   "metadata": {},
   "outputs": [],
   "source": [
    "A[1, :] = A[2, :]  # Slice indexing still allowed!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funny-shannon",
   "metadata": {},
   "source": [
    "### Example: Power iteration\n",
    "\n",
    "As demonstrated above, there is barely any difference between GPU and CPU Julia code ... and that's the great power! Let's see this in practice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "consolidated-sperm",
   "metadata": {},
   "outputs": [],
   "source": [
    "function power_iteration(A, x; tol=1e-4, maxiter=100, display_progress=true)\n",
    "    x  = x / norm(x)\n",
    "    Ax = similar(x)  # Allocate scratch memory\n",
    "    λ  = zero(eltype(Ax))\n",
    "    for i = 1:maxiter\n",
    "        mul!(Ax, A, x)\n",
    "        λ = x'Ax\n",
    "        display_progress && println(\"iter $i $λ\")\n",
    "        Ax ./= norm(Ax)\n",
    "        sqrt(abs(1 - Ax'x)) < tol && return λ, Ax\n",
    "        x .= Ax\n",
    "    end\n",
    "    λ, x\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "answering-zimbabwe",
   "metadata": {},
   "source": [
    "Use it with CPUs as usual:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chinese-element",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = randn(Float32, 100, 100)\n",
    "A = A + A' + 10I\n",
    "x = rand(Float32, 100)\n",
    "\n",
    "λ, _ = power_iteration(A, x, display_progress=false)\n",
    "λ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metric-easter",
   "metadata": {},
   "source": [
    "Use it on the GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pretty-dealing",
   "metadata": {},
   "outputs": [],
   "source": [
    "λ, _ = power_iteration(cu(A), cu(x), display_progress=false)\n",
    "λ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "framed-gospel",
   "metadata": {},
   "source": [
    "### Example: Poisson's equation on the GPU\n",
    "\n",
    "We wish to solve $ \\Delta x = ρ $ on $[0, 1]$ where\n",
    "$ ρ(r) = δ(x) -2δ(x - 0.5)$. We discretise using finite differences using $100$ grid points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proved-buyer",
   "metadata": {},
   "outputs": [],
   "source": [
    "using SparseArrays\n",
    "N = 101\n",
    "\n",
    "# Prepare input on the CPU\n",
    "Δ = spdiagm(0 => 2ones(Float32, N), 1=>-ones(Float32, N-1), -1 => -ones(Float32, N-1))\n",
    "ρ = zeros(N)\n",
    "ρ[1] = 1\n",
    "ρ[Int((N-1)/2)] = -2\n",
    "\n",
    "# Send to device:\n",
    "Δ_d = cu(Δ)\n",
    "ρ_d = cu(ρ)\n",
    "\n",
    "Δ_d   # Note: Structure is kept!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "focused-corporation",
   "metadata": {},
   "outputs": [],
   "source": [
    "using IterativeSolvers\n",
    "\n",
    "# Solve using a CG (on the device!)\n",
    "x = cg(Δ_d, ρ_d, verbose=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regular-ministry",
   "metadata": {},
   "source": [
    "## Low-level tour"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "possible-tolerance",
   "metadata": {},
   "source": [
    "### Unsupported functions\n",
    "\n",
    "Many CUDA functions are directly supported from the high-level Julia interfaces. Unfortunately some are not. Some examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uniform-measurement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LAPACK-like call from CUSOLVER\n",
    "\n",
    "A = CUDA.randn(4, 4)\n",
    "A = A + A'\n",
    "eigen(A)  # Oh that would be so nice ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "relative-remains",
   "metadata": {},
   "outputs": [],
   "source": [
    "# But this works ...\n",
    "λ, v = CUDA.CUSOLVER.syevd!('V', 'U', A)   # Like LAPACKs \"syevd\"\n",
    "@show λ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "integrated-legislature",
   "metadata": {},
   "source": [
    "### Custom kernels\n",
    "\n",
    "This is where the real power starts ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noticed-sister",
   "metadata": {},
   "outputs": [],
   "source": [
    "function gpuadd_sequential!(y, x)\n",
    "    for i = 1:length(y)\n",
    "        @inbounds y[i] += x[i]\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finnish-houston",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = 2CUDA.ones(1000)\n",
    "x =  CUDA.ones(1000)\n",
    "@cuda gpuadd_sequential!(y, x)  # Call the kernel\n",
    "all(Array(y) .== 3.0f0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regional-taste",
   "metadata": {},
   "source": [
    "How long did that take?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "biblical-projector",
   "metadata": {},
   "outputs": [],
   "source": [
    "@btime CUDA.@sync @cuda gpuadd_sequential!($y, $x);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cheap-logistics",
   "metadata": {},
   "source": [
    "Parallelise ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "female-glass",
   "metadata": {},
   "outputs": [],
   "source": [
    "function gpuadd!(y, x)\n",
    "    index  = threadIdx().x\n",
    "    stride = blockDim().x    \n",
    "    for i = index:stride:length(y)\n",
    "        @inbounds y[i] += x[i]\n",
    "    end\n",
    "end\n",
    "\n",
    "y = 2CUDA.ones(1000)\n",
    "x =  CUDA.ones(1000)\n",
    "@cuda threads=256 gpuadd!(y, x)  # Call the kernel\n",
    "all(Array(y) .== 3.0f0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "usual-idaho",
   "metadata": {},
   "outputs": [],
   "source": [
    "@btime CUDA.@sync @cuda threads=256 gpuadd!($y, $x);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collect-bankruptcy",
   "metadata": {},
   "source": [
    "Kernels for both GPU and CPU: [KernelAbstractions.jl](https://github.com/JuliaGPU/KernelAbstractions.jl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "leading-bobby",
   "metadata": {},
   "source": [
    "### See what's going on\n",
    "\n",
    "- `nvidia-smi`\n",
    "- NSight Systems `nsys` and `CUDA.@profile`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "limiting-firewall",
   "metadata": {},
   "source": [
    "## Overview: What is supported\n",
    "\n",
    "- General factorisations (Cholesky, QR, ...)\n",
    "- Dense linear solves\n",
    "- Sparse arrays\n",
    "- CUDA FFTs\n",
    "- Most BLAS, LAPACK\n",
    "- Plenty of nice packages (IterativeSolvers)\n",
    "- [Profiling](https://juliagpu.github.io/CUDA.jl/stable/development/profiling/)\n",
    "- ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "virgin-somerset",
   "metadata": {},
   "source": [
    "## Closing example: LOBPCG\n",
    "\n",
    "So how would one go about implement something on the GPU. We will take a look at [lobpcg.jl](lobpcg.jl), which is a (crappy) CPU version of a sophisticated iterative diagonalisation algorithm. To implement it on the GPU these are the steps to follow:\n",
    "\n",
    "1. Implement it on CPU (done)\n",
    "2. Profiling and performance optimisation on CPU (skipped ... but really should be done first!)\n",
    "3. Get it to work on the GPU\n",
    "4. Turn off scalar indexing, fix all issues\n",
    "5. Profile on GPU\n",
    "6. Implement custom kernels if needed\n",
    "\n",
    "Ok, so let's go with step 3 ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.0",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
